name: NativeMimic v4.0 Testing Pipeline

on:
  push:
    branches: [ main, develop, 'feature/*', 'bugfix/*', 'hotfix/*' ]
  pull_request:
    branches: [ main, develop ]

env:
  NODE_VERSION: '18'
  CACHE_VERSION: v1

jobs:
  # Quick smoke tests for fast feedback
  smoke-tests:
    name: Smoke Tests
    runs-on: ubuntu-latest
    timeout-minutes: 5
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Run smoke tests
        run: npm run test:smoke
        
      - name: Upload smoke test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: smoke-test-results
          path: coverage/test-results.json

  # Unit tests with coverage
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: smoke-tests
    
    strategy:
      matrix:
        node-version: [18, 20]
        
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Run TypeScript type checking
        run: npm run type-check
        
      - name: Run linting
        run: npm run lint
        
      - name: Run unit tests with coverage
        run: npm run test:coverage
        
      - name: Check coverage thresholds
        run: |
          # Fail if coverage is below 95%
          npx nyc check-coverage --lines 95 --functions 95 --branches 90 --statements 95
        
      - name: Upload coverage to Codecov
        if: matrix.node-version == 18
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage/lcov.info
          fail_ci_if_error: true
          
      - name: Upload unit test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: unit-test-results-node${{ matrix.node-version }}
          path: |
            coverage/
            test-results/

  # Integration tests
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: unit-tests
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Start test services
        run: npm run setup:test-env
        
      - name: Run integration tests
        run: npm run test:integration
        
      - name: Upload integration test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: integration-test-results
          path: coverage/test-results.json

  # Performance tests
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: unit-tests
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Run performance tests
        run: npm run test:performance
        
      - name: Check performance regressions
        run: |
          # Custom script to check for performance regressions
          node scripts/check-performance-regression.js
        
      - name: Upload performance results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-test-results
          path: coverage/test-results.json

  # Cross-browser E2E tests
  e2e-tests:
    name: E2E Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [unit-tests, integration-tests]
    
    strategy:
      matrix:
        browser: [chromium, firefox]
        
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Install Playwright browsers
        run: npx playwright install --with-deps ${{ matrix.browser }}
        
      - name: Build extension for testing
        run: npm run build:test
        
      - name: Start test environment
        run: npm run setup:test-env &
        
      - name: Wait for test environment
        run: |
          timeout 30 bash -c 'until curl -f http://localhost:3000; do sleep 1; done'
        
      - name: Run E2E tests
        run: npx playwright test --project=${{ matrix.browser }}
        
      - name: Upload E2E test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-test-results-${{ matrix.browser }}
          path: |
            playwright-report/
            test-results/
            
      - name: Upload screenshots on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-screenshots-${{ matrix.browser }}
          path: test-results/

  # Security and compliance tests
  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: smoke-tests
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Run security audit
        run: npm audit --audit-level moderate
        
      - name: Check for known vulnerabilities
        run: npx audit-ci --moderate
        
      - name: Run license compliance check
        run: npx license-checker --onlyAllow 'MIT;Apache-2.0;BSD-2-Clause;BSD-3-Clause;ISC'
        
      - name: Scan for secrets
        uses: trufflesecurity/trufflehog@main
        with:
          path: ./
          base: main
          head: HEAD

  # Build verification
  build-verification:
    name: Build Verification
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: smoke-tests
    
    strategy:
      matrix:
        build-mode: [development, production, test]
        
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Build extension (${{ matrix.build-mode }})
        run: |
          if [ "${{ matrix.build-mode }}" = "production" ]; then
            npm run build
          elif [ "${{ matrix.build-mode }}" = "test" ]; then
            npm run build:test
          else
            npm run build:dev
          fi
        
      - name: Validate build artifacts
        run: |
          # Check that required files exist
          [ -f "dist/manifest.json" ] || exit 1
          [ -f "dist/background.js" ] || exit 1
          [ -f "dist/content.js" ] || exit 1
          
          # Validate manifest.json
          node -e "JSON.parse(require('fs').readFileSync('dist/manifest.json', 'utf8'))"
          
          # Check file sizes are reasonable
          MANIFEST_SIZE=$(stat -c%s "dist/manifest.json")
          [ $MANIFEST_SIZE -lt 10000 ] || exit 1  # Less than 10KB
          
        - name: Package extension
          run: npm run extension:pack
          
        - name: Upload build artifacts
          uses: actions/upload-artifact@v4
          with:
            name: extension-build-${{ matrix.build-mode }}
            path: |
              dist/
              artifacts/

  # Test result aggregation and reporting
  test-results:
    name: Test Results Summary
    runs-on: ubuntu-latest
    needs: [smoke-tests, unit-tests, integration-tests, performance-tests, e2e-tests, security-tests, build-verification]
    if: always()
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Download all test artifacts
        uses: actions/download-artifact@v4
        with:
          path: test-artifacts/
          
      - name: Generate test summary
        run: |
          echo "# NativeMimic v4.0 Test Results Summary" > test-summary.md
          echo "" >> test-summary.md
          echo "**Commit:** ${{ github.sha }}" >> test-summary.md
          echo "**Branch:** ${{ github.ref_name }}" >> test-summary.md
          echo "**Workflow:** ${{ github.workflow }}" >> test-summary.md
          echo "**Run:** ${{ github.run_number }}" >> test-summary.md
          echo "" >> test-summary.md
          
          # Check job results
          echo "## Job Results" >> test-summary.md
          echo "| Job | Status |" >> test-summary.md
          echo "|-----|--------|" >> test-summary.md
          echo "| Smoke Tests | ${{ needs.smoke-tests.result }} |" >> test-summary.md
          echo "| Unit Tests | ${{ needs.unit-tests.result }} |" >> test-summary.md
          echo "| Integration Tests | ${{ needs.integration-tests.result }} |" >> test-summary.md
          echo "| Performance Tests | ${{ needs.performance-tests.result }} |" >> test-summary.md
          echo "| E2E Tests | ${{ needs.e2e-tests.result }} |" >> test-summary.md
          echo "| Security Tests | ${{ needs.security-tests.result }} |" >> test-summary.md
          echo "| Build Verification | ${{ needs.build-verification.result }} |" >> test-summary.md
          echo "" >> test-summary.md
          
          # Add performance metrics if available
          if [ -f "test-artifacts/performance-test-results/test-results.json" ]; then
            echo "## Performance Metrics" >> test-summary.md
            node scripts/parse-performance-results.js >> test-summary.md
          fi
          
          # Add coverage information if available
          if [ -f "test-artifacts/unit-test-results-node18/lcov.info" ]; then
            echo "## Code Coverage" >> test-summary.md
            echo "Coverage report available in artifacts." >> test-summary.md
          fi
          
      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync('test-summary.md', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });
            
      - name: Upload test summary
        uses: actions/upload-artifact@v4
        with:
          name: test-summary
          path: test-summary.md
          
      - name: Fail if critical tests failed
        if: |
          needs.smoke-tests.result == 'failure' ||
          needs.unit-tests.result == 'failure' ||
          needs.security-tests.result == 'failure'
        run: |
          echo "Critical tests failed. Blocking deployment."
          exit 1

  # Regression testing against v3.16 baseline
  regression-tests:
    name: Regression Tests (vs v3.16)
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: [unit-tests, performance-tests]
    if: github.ref == 'refs/heads/main' || github.event_name == 'pull_request'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Run regression test suite
        run: npm run test:regression
        
      - name: Compare with v3.16 baseline
        run: |
          # Run specific regression tests that check for v3.16 issues
          npx playwright test --grep "@regression"
          
      - name: Upload regression test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: regression-test-results
          path: |
            playwright-report/
            test-results/

# Deployment readiness check
  deployment-ready:
    name: Deployment Readiness
    runs-on: ubuntu-latest
    needs: [test-results, regression-tests]
    if: |
      always() &&
      needs.test-results.result == 'success' &&
      (needs.regression-tests.result == 'success' || needs.regression-tests.result == 'skipped')
    
    steps:
      - name: Deployment ready notification
        run: |
          echo "✅ All tests passed! Ready for deployment."
          echo "Branch: ${{ github.ref_name }}"
          echo "Commit: ${{ github.sha }}"
          
      - name: Create deployment artifact
        run: |
          echo "DEPLOYMENT_READY=true" > deployment.env
          echo "BUILD_SHA=${{ github.sha }}" >> deployment.env
          echo "BUILD_BRANCH=${{ github.ref_name }}" >> deployment.env
          echo "BUILD_NUMBER=${{ github.run_number }}" >> deployment.env
          
      - name: Upload deployment readiness
        uses: actions/upload-artifact@v4
        with:
          name: deployment-ready
          path: deployment.env